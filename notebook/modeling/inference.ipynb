{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the necessary libraries\n",
    "import joblib\n",
    "import os\n",
    "import hyperopt\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sb\n",
    "import scipy.stats as st\n",
    "from datetime import datetime \n",
    "from sklearn.utils import resample\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyoff\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from warnings import simplefilter\n",
    "from sklearn.cluster import KMeans\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from skopt  import BayesSearchCV\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import ( beta, expon, randint, uniform)\n",
    "from sklearn.base import (TransformerMixin, BaseEstimator)\n",
    "from sklearn.metrics import ( roc_curve, auc, accuracy_score, roc_auc_score,log_loss,confusion_matrix,classification_report)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import ( FeatureUnion, Pipeline )\n",
    "from sklearn.preprocessing import ( OneHotEncoder, LabelBinarizer, LabelEncoder, StandardScaler, MinMaxScaler, MaxAbsScaler )\n",
    "from sklearn.model_selection import ( GridSearchCV, StratifiedKFold, train_test_split, cross_val_score, RandomizedSearchCV, KFold )\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = '../../models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataPreprocessing(object):\n",
    "\n",
    "    def load_data(self, data):\n",
    "        \"\"\" Method to load data from json file\"\"\"\n",
    "        df = None\n",
    "        if os.path.isdir(data):\n",
    "            if str(data).split('.')[-1]=='json':\n",
    "                df = pd.read_json(data)\n",
    "            \n",
    "            if str(data).split('.')[-1]=='xlsx':\n",
    "                df = pd.read_ecel(data)\n",
    "\n",
    "            if str(data).split('.')[-1]=='csv':\n",
    "                df = pd.read_csv(data)\n",
    "        else:\n",
    "            df = pd.read_json(data)\n",
    "        return df\n",
    "\n",
    "    def drop_nan(self, data):\n",
    "        \"\"\"Method that takes in a text and removes all null values.\"\"\"\n",
    "        return data.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "    def drop_duplicates(self, data):\n",
    "        \"\"\"Method that takes in a text and removes all null values.\"\"\"\n",
    "        return data.drop_duplicates(keep='last').reset_index(drop=True)\n",
    "\n",
    "    def string_to_date(self, data, column='paid_at'):\n",
    "        \"\"\"Method that converts date to string datetime.\"\"\"\n",
    "        data[column] = pd.to_datetime(data[column])\n",
    "        return  data\n",
    "\n",
    "    def string_to_date(self, data, column='paid_at'):\n",
    "        \"\"\"Method that converts date to string datetime.\"\"\"\n",
    "        data[column] = pd.to_datetime(data[column])\n",
    "        return  data\n",
    "\n",
    "    def previous_data(self, data,from_date, to_date, column='paid_at'):\n",
    "        \"\"\"Method that return purchase behaviour for last defined time period.\"\"\"\n",
    "        return data[(data[column] < to_date) & (data[column] >= from_date)].reset_index(drop=True)\n",
    "\n",
    "    def next_data(self, data,column, from_date, to_date):\n",
    "        \"\"\"Method that returns the next data for check first purchase after the last time.\"\"\"\n",
    "        return data[(data[column] >= from_date) & (data[column] < to_date)].reset_index(drop=True)\n",
    "\n",
    "    def get_customers(self, data, column='customer_id'):\n",
    "        \"\"\"filter unique customer who did purchase in previous 9 months.\"\"\"\n",
    "        customers = pd.DataFrame(data[column].unique())\n",
    "        customers.columns = [column]\n",
    "        return customers\n",
    "    \n",
    "    def get_last_purchase(self, previous_data, column='customer_id'):\n",
    "        \"\"\"create a dataframe with customer id and last purchase date in invoices_next.\"\"\"\n",
    "        last_purchase =previous_data.groupby(column).paid_at.max().reset_index()\n",
    "        last_purchase.columns = [column,'max_purchase_date']\n",
    "        return last_purchase\n",
    "\n",
    "    def get_next_first_purchase(self, next_data, column='customer_id'):\n",
    "        \"\"\"create a dataframe with customer id and first purchase date in next\"\"\"\n",
    "        next_first_purchase = next_data.groupby('customer_id').paid_at.min().reset_index()\n",
    "        next_first_purchase.columns = ['customer_id','min_purchase_date']\n",
    "        return next_first_purchase\n",
    "        \n",
    "    def join_last_first_purchases(self, last_purchase, next_first_purchase, column='customer_id'):\n",
    "        \"\"\"merge two dataframes [last purchase and first purchase]\"\"\"\n",
    "        return pd.merge(last_purchase,next_first_purchase,on=column,how='left')\n",
    "\n",
    "    def get_time_difference_between_purchases(self, purchases):\n",
    "        \"\"\"calculate the time difference in days:\"\"\"\n",
    "        purchases['next_purchase_day'] = (purchases['min_purchase_date'] - purchases['max_purchase_date']).dt.days\n",
    "        return purchases \n",
    "\n",
    "    def assign_time_difference_to_customers(self, customers, time_difference):\n",
    "        \"\"\" merge time difference with customers\"\"\"\n",
    "        customers_time_difference = pd.merge(customers, time_difference[['customer_id','next_purchase_day']],on='customer_id',how='left')\n",
    "        return customers_time_difference\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessor = DataPreprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = data_preprocessor.load_data('../../../data/datapoint.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>admin_id</th>\n",
       "      <th>deliverer_id</th>\n",
       "      <th>returned_items</th>\n",
       "      <th>discount</th>\n",
       "      <th>refund</th>\n",
       "      <th>total</th>\n",
       "      <th>items_count</th>\n",
       "      <th>...</th>\n",
       "      <th>paid_at</th>\n",
       "      <th>is_processed</th>\n",
       "      <th>is_informed</th>\n",
       "      <th>notification_count</th>\n",
       "      <th>status</th>\n",
       "      <th>is_received</th>\n",
       "      <th>processed_at</th>\n",
       "      <th>tagname</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1158</td>\n",
       "      <td>0</td>\n",
       "      <td>38572</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-01 07:38:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unpaid</td>\n",
       "      <td>0</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-01 10:38:06</td>\n",
       "      <td>2022-05-01 10:38:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1426</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-01 10:44:03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paid</td>\n",
       "      <td>0</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-01 10:42:34</td>\n",
       "      <td>2022-05-19 10:36:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  customer_id  admin_id  deliverer_id  returned_items  \\\n",
       "4           4   6            6         0           NaN               0   \n",
       "5           5   7            6         0           2.0               0   \n",
       "\n",
       "   discount  refund  total  items_count  ...             paid_at  \\\n",
       "4      1158       0  38572            1  ... 2022-05-01 07:38:06   \n",
       "5         0       0   1426            2  ... 2022-05-01 10:44:03   \n",
       "\n",
       "   is_processed  is_informed  notification_count  status  is_received  \\\n",
       "4             0            0                   0  Unpaid            0   \n",
       "5             1            0                   0    Paid            0   \n",
       "\n",
       "          processed_at  tagname          created_at          updated_at  \n",
       "4  0000-00-00 00:00:00      NaN 2022-05-01 10:38:06 2022-05-01 10:38:13  \n",
       "5  0000-00-00 00:00:00      NaN 2022-05-01 10:42:34 2022-05-19 10:36:29  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_point[:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = data_preprocessor.drop_nan(data_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date field from string to datetime\n",
    "data_point = data_preprocessor.string_to_date(data_point,'paid_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose 30 November as a cutt of date (1, Jan - 30 November) for behaviour data\n",
    "data_point_previous = data_preprocessor.previous_data(data = data_point, from_date = datetime(2022,1,1,00,00,00), to_date= datetime(2022,11,30,23,59,00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data after cut off date (1 month window), to check for next purchase\n",
    "data_point_next = data_preprocessor.previous_data(data = data_point, from_date = datetime(2022,11,30,23,59,00), to_date= datetime(2022,12,31,23,59,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter unique customer who did purchase in previous 9 months\n",
    "data_point_customer_previous = data_preprocessor.get_customers(data_point_previous, column='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id\n",
       "0            6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_point_customer_previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with customer id and last purchase date in invoices_previous\n",
    "last_purchase_data_point = data_preprocessor.get_last_purchase(data_point_previous, column='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>max_purchase_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-11-30 08:19:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id   max_purchase_date\n",
       "0            6 2022-11-30 08:19:40"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_purchase_data_point.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with customer id and first purchase date in next\n",
    "next_first_purchase_data_point = data_preprocessor.get_next_first_purchase(data_point_next, column='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>min_purchase_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-12-01 12:18:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id   min_purchase_date\n",
       "0            6 2022-12-01 12:18:15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_first_purchase_data_point.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge two dataframes [last purchase and first purchase]\n",
    "purchase_dates = data_preprocessor.join_last_first_purchases(last_purchase_data_point, next_first_purchase_data_point, column='customer_id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>max_purchase_date</th>\n",
       "      <th>min_purchase_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-11-30 08:19:40</td>\n",
       "      <td>2022-12-01 12:18:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id   max_purchase_date   min_purchase_date\n",
       "0            6 2022-11-30 08:19:40 2022-12-01 12:18:15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_dates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the time difference in days:\n",
    "purchase_dates = data_preprocessor.get_time_difference_between_purchases(purchases=purchase_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>max_purchase_date</th>\n",
       "      <th>min_purchase_date</th>\n",
       "      <th>next_purchase_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-11-30 08:19:40</td>\n",
       "      <td>2022-12-01 12:18:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id   max_purchase_date   min_purchase_date  next_purchase_day\n",
       "0            6 2022-11-30 08:19:40 2022-12-01 12:18:15                  1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_dates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesGeneration():\n",
    "\n",
    "    def recency(self, data_point_previous, data_point_customer_previous):\n",
    "        #get max purchase date for Recency and create a dataframe of the last purchase before cut off date\n",
    "        invoices_max_purchase = data_point_previous.groupby('customer_id').paid_at.max().reset_index()\n",
    "        invoices_max_purchase.columns = ['customer_id','max_purchase_date']\n",
    "\n",
    "        #find the recency in days and add it to invoices_customers, given as the day difference between the last purchase before cut off, and other purchases before cut of\n",
    "        invoices_max_purchase['Recency'] = (invoices_max_purchase['max_purchase_date'].max() - invoices_max_purchase['max_purchase_date']).dt.days\n",
    "        data_point_customer_previous = pd.merge(data_point_customer_previous, invoices_max_purchase[['customer_id','Recency']], on='customer_id')\n",
    "\n",
    "        return data_point_customer_previous\n",
    "\n",
    "    def recency_cluster(self, data_point_customer_previous):\n",
    "        #clustering for Recency, use elbow method to determine the number of clusters\n",
    "        import joblib\n",
    "        kmeans_recency = joblib.load(MODELS_PATH+'kmeans_recency.joblib')\n",
    "        data_point_customer_previous['RecencyCluster'] = kmeans_recency.predict(data_point_customer_previous[['Recency']])\n",
    "        return data_point_customer_previous\n",
    "\n",
    "    def frequency(self, data_point_previous, data_point_customer_previous):\n",
    "        #get total purchases for frequency scores\n",
    "        invoices_frequency = data_point_previous.groupby('customer_id').paid_at.count().reset_index()\n",
    "        invoices_frequency.columns = ['customer_id','Frequency']\n",
    "        #add frequency column to invoices_customers\n",
    "        data_point_customer_previous = pd.merge(data_point_customer_previous, invoices_frequency, on='customer_id')\n",
    "        return data_point_customer_previous\n",
    "\n",
    "    def frequency_cluster(self,data_point_customer_previous):\n",
    "        #clustering for frequency\n",
    "        import joblib\n",
    "        kmeans_frequency = joblib.load(MODELS_PATH+'kmeans_frequency.joblib')\n",
    "        data_point_customer_previous['FrequencyCluster'] = kmeans_frequency.predict(data_point_customer_previous[['Frequency']])\n",
    "        return data_point_customer_previous\n",
    "\n",
    "    def monetary_value(self,data_point_previous, data_point_customer_previous):\n",
    "        #calculate monetary value, create a dataframe with it\n",
    "        data_point_previous['Revenue'] = data_point_previous['amount'] *data_point_previous['items_count']\n",
    "        invoices_revenue = data_point_previous.groupby('customer_id').Revenue.sum().reset_index()\n",
    "        #add Revenue column to invoices_customers\n",
    "        data_point_customer_previous = pd.merge(data_point_customer_previous, invoices_revenue, on='customer_id')\n",
    "        return data_point_customer_previous\n",
    "\n",
    "    def revenue_cluster(self,data_point_customer_previous):\n",
    "        #Revenue clusters \n",
    "        import joblib\n",
    "        kmeans_revenue = joblib.load(MODELS_PATH+'kmeans_revenue.joblib')\n",
    "        data_point_customer_previous['RevenueCluster'] = kmeans_revenue.predict(data_point_customer_previous[['Revenue']])\n",
    "        return data_point_customer_previous\n",
    "\n",
    "    def overall_score(self, data_point_customer_previous):\n",
    "        #building overall segmentation\n",
    "         data_point_customer_previous['OverallScore'] =  data_point_customer_previous['RecencyCluster'] +  data_point_customer_previous['FrequencyCluster'] +  data_point_customer_previous['RevenueCluster']\n",
    "         return  data_point_customer_previous\n",
    "\n",
    "    def segments(self, data_point_customer_previous):\n",
    "        #assign segment names\n",
    "        data_point_customer_previous['Segment'] = 'Low-Value'\n",
    "        data_point_customer_previous.loc[data_point_customer_previous['OverallScore']>2,'Segment'] = 'Mid-Value' \n",
    "        data_point_customer_previous.loc[data_point_customer_previous['OverallScore']>4,'Segment'] = 'High-Value' \n",
    "        return data_point_customer_previous\n",
    "\n",
    "    def trace_back_three(self, data_point_previous, data_point_customer_previous):\n",
    "        #create a dataframe with customer_id and Invoice Date\n",
    "        invoices_day_order = data_point_previous[['customer_id','paid_at']]\n",
    "        #convert Invoice Datetime to day\n",
    "        invoices_day_order['InvoiceDay'] = data_point_previous['paid_at'].dt.date\n",
    "        invoices_day_order = invoices_day_order.sort_values(['customer_id','paid_at'])\n",
    "        #drop duplicates\n",
    "        invoices_day_order = invoices_day_order.drop_duplicates(subset=['customer_id','InvoiceDay'],keep='first')\n",
    "        #shifting last 3 purchase dates\n",
    "        invoices_day_order['PrevInvoiceDate'] = invoices_day_order.groupby('customer_id')['InvoiceDay'].shift(1)\n",
    "        invoices_day_order['T2InvoiceDate'] = invoices_day_order.groupby('customer_id')['InvoiceDay'].shift(2)\n",
    "        invoices_day_order['T3InvoiceDate'] = invoices_day_order.groupby('customer_id')['InvoiceDay'].shift(3)\n",
    "        #calculate the day differences between purchases (the 3 purchases gaps)\n",
    "        invoices_day_order['DayDiff'] = (invoices_day_order['InvoiceDay'] - invoices_day_order['PrevInvoiceDate']).dt.days\n",
    "        invoices_day_order['DayDiff2'] = (invoices_day_order['InvoiceDay'] - invoices_day_order['T2InvoiceDate']).dt.days\n",
    "        invoices_day_order['DayDiff3'] = (invoices_day_order['InvoiceDay'] - invoices_day_order['T3InvoiceDate']).dt.days\n",
    "        #find the mean day difference , and std \n",
    "        invoices_day_diff = invoices_day_order.groupby('customer_id').agg({'DayDiff': ['mean','std']}).reset_index()\n",
    "        invoices_day_diff.columns = ['customer_id', 'DayDiffMean','DayDiffStd']\n",
    "        ##we have customers who purchased only one time, We can't keep customer who has purchased one time, for this case we keep customer who has purchased atleast 3 times\n",
    "        invoices_day_order_last = invoices_day_order.drop_duplicates(subset=['customer_id'],keep='last') # filter with one purchase\n",
    "\n",
    "        invoices_day_order_last = invoices_day_order_last.dropna()\n",
    "        invoices_day_order_last = pd.merge(invoices_day_order_last, invoices_day_diff, on='customer_id')\n",
    "        data_point_customer_previous = pd.merge(data_point_customer_previous, invoices_day_order_last[['customer_id','DayDiff','DayDiff2','DayDiff3','DayDiffMean','DayDiffStd']], on='customer_id')\n",
    "        return data_point_customer_previous\n",
    "\n",
    "    def dummy_data(self, data_point_customer_previous):\n",
    "        #create invoices_class as a copy of invoices_customers before applying get_dummies\n",
    "        invoices_class = data_point_customer_previous.copy()\n",
    "        invoices_class = pd.get_dummies(invoices_class)\n",
    "        # drop less importand columns as per trining\n",
    "        features_generated  = invoices_class.drop(['DayDiff', 'DayDiff3', 'DayDiff2', 'Recency', 'DayDiffMean','DayDiffStd'], axis=1)\n",
    "        return features_generated\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_generator = FeaturesGeneration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add recency feature \n",
    "data_point_customer_previous = features_generator.recency(data_point_previous=data_point_previous, data_point_customer_previous=data_point_customer_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add recency cluster\n",
    "data_point_customer_previous = features_generator.recency_cluster(data_point_customer_previous=data_point_customer_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add frequency\n",
    "data_point_customer_previous = features_generator.frequency(data_point_previous=data_point_previous, data_point_customer_previous=data_point_customer_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>Recency</th>\n",
       "      <th>RecencyCluster</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  Recency  RecencyCluster  Frequency\n",
       "0            6        0               4         88"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_point_customer_previous[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add frequency cluster\n",
    "data_point_customer_previous = features_generator.frequency_cluster(data_point_customer_previous=data_point_customer_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Money value\n",
    "data_point_customer_previous = features_generator.monetary_value(data_point_previous=data_point_previous, data_point_customer_previous=data_point_customer_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add money cluster\n",
    "data_point_customer_previous = features_generator.revenue_cluster(data_point_customer_previous=data_point_customer_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add overall score\n",
    "data_point_customer_previous = features_generator.overall_score(data_point_customer_previous=data_point_customer_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add segments\n",
    "data_point_customer_previous = features_generator.segments(data_point_customer_previous=data_point_customer_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15482/2554567446.py:67: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add trace back tree purchases\n",
    "data_point_customer_previous = features_generator.trace_back_three(data_point_previous=data_point_previous, data_point_customer_previous=data_point_customer_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>Recency</th>\n",
       "      <th>RecencyCluster</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>FrequencyCluster</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>RevenueCluster</th>\n",
       "      <th>OverallScore</th>\n",
       "      <th>Segment</th>\n",
       "      <th>DayDiff</th>\n",
       "      <th>DayDiff2</th>\n",
       "      <th>DayDiff3</th>\n",
       "      <th>DayDiffMean</th>\n",
       "      <th>DayDiffStd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>218880079</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>High-Value</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.018868</td>\n",
       "      <td>3.499948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  Recency  RecencyCluster  Frequency  FrequencyCluster  \\\n",
       "0            6        0               4         88                 4   \n",
       "\n",
       "     Revenue  RevenueCluster  OverallScore     Segment  DayDiff  DayDiff2  \\\n",
       "0  218880079               3            11  High-Value      2.0       6.0   \n",
       "\n",
       "   DayDiff3  DayDiffMean  DayDiffStd  \n",
       "0       8.0     4.018868    3.499948  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_point_customer_previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add segments\n",
    "data_point_customer_previous_features = features_generator.dummy_data(data_point_customer_previous=data_point_customer_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a class for numerical data tansformation\n",
    "class Transform(TransformerMixin,BaseEstimator):\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=0):\n",
    "        num_pipeline = Pipeline([('scaler',StandardScaler())])\n",
    "        X = num_pipeline.fit_transform(X)\n",
    "        return pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform =  Transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point_customer_previous_features = transform.fit_transform(data_point_customer_previous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(data_point_features):\n",
    "    model = joblib.load(MODELS_PATH+'lgbm_optim.joblib')\n",
    "    inference_results = model.predict_proba(data_point_features)\n",
    "    inference_results_df_probas= pd.DataFrame(data=inference_results,columns=['Purchase','Not Purchase'])\n",
    "    inference_label = 1 if np.amax(inference_results)>=0.5 else 0\n",
    "    if inference_label == 1:\n",
    "        print(\"Customer is {:.2f}% likely to purchase in the coming 1 month\".format(np.amax(inference_results)*100))\n",
    "    elif inference_label == 0:\n",
    "        print(\"Customer is {:.2f}% unlikely to purchase in the coming 1 month\".format(np.amax(inference_results)*100))\n",
    "    else:\n",
    "        print('Unpredictable')\n",
    "    return inference_results, inference_results_df_probas, inference_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer is 75.58% likely to purchase in the coming 1 month\n"
     ]
    }
   ],
   "source": [
    "inference_results,inference_results_df_probas,inference_label = inference(data_point_customer_previous_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
